{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b6eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93296e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6723a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>token_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>appartment old need make holes need owner agre...</td>\n",
       "      <td>0</td>\n",
       "      <td>appartment old need make holes need owner agre...</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>castlenes havent you dislike handwriting im he...</td>\n",
       "      <td>1</td>\n",
       "      <td>castlenes havent you dislike handwriting im he...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>guavawrite good see you ill get bigmouths foll...</td>\n",
       "      <td>1</td>\n",
       "      <td>guavawrite good see you ill get bigmouths foll...</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>goodnight space mountain spending next week pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>goodnight space mountain spending next week pa...</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>frankmusik big load grey boobs hope grey thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>frankmusik big load grey boobs hope grey thing...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          TweetText  sentiment  \\\n",
       "0           0  appartment old need make holes need owner agre...          0   \n",
       "1           1  castlenes havent you dislike handwriting im he...          1   \n",
       "2           2  guavawrite good see you ill get bigmouths foll...          1   \n",
       "3           3  goodnight space mountain spending next week pa...          0   \n",
       "4           4  frankmusik big load grey boobs hope grey thing...          1   \n",
       "\n",
       "                                          text_clean  text_len  token_lens  \n",
       "0  appartment old need make holes need owner agre...        11          16  \n",
       "1  castlenes havent you dislike handwriting im he...         7          11  \n",
       "2  guavawrite good see you ill get bigmouths foll...         9          15  \n",
       "3  goodnight space mountain spending next week pa...        12          17  \n",
       "4  frankmusik big load grey boobs hope grey thing...        13          18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b641251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#how many epochs?\n",
    "EPOCHS = 8\n",
    "\n",
    "#clean Tweets?\n",
    "CLEAN_TWEETS = False\n",
    "\n",
    "#use meta data?\n",
    "USE_META = True\n",
    "\n",
    "#add dense layer?\n",
    "ADD_DENSE = False\n",
    "DENSE_DIM = 64\n",
    "\n",
    "#add dropout?\n",
    "ADD_DROPOUT = True\n",
    "DROPOUT = .2\n",
    "\n",
    "#train BERT base model? \n",
    "TRAIN_BASE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04e07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the basics\n",
    "import os, re, math, string, pandas as pd, numpy as np, seaborn as sns\n",
    "\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "\n",
    "#nlp\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20145baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "train_x, train_y = ros.fit_resample(np.array(df['text_clean']).reshape(-1, 1), np.array(df['sentiment']).reshape(-1, 1));\n",
    "train_os = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text_clean', 'sentiment']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c5e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_os['text_clean'].values\n",
    "y = train_os['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319c607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86907e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43e5967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#get BERT layer\n",
    "bert_base = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "#bert_base = BertModel.from_pretrained('bert-base-uncased')          #to use with PyTorch\n",
    "\n",
    "#select BERT tokenizer\n",
    "TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fd4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bert_encode(data,maximum_len) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "  \n",
    "\n",
    "    for i in range(len(data)):\n",
    "        encoded = TOKENIZER.encode_plus(data[i],\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=maximum_len,\n",
    "                                        pad_to_max_length=True,\n",
    "                                        return_attention_mask=True)\n",
    "      \n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "        \n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdb9acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_layer, learning_rate, use_meta = USE_META, add_dense = ADD_DENSE,\n",
    "               dense_dim = DENSE_DIM, add_dropout = ADD_DROPOUT, dropout = DROPOUT):\n",
    "    \n",
    "    #define inputs\n",
    "    input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    # meta_input = tf.keras.Input(shape = (meta_train.shape[1], ))\n",
    "    \n",
    "    #insert BERT layer\n",
    "    transformer_layer = model_layer([input_ids,attention_masks])\n",
    "    \n",
    "    #choose only last hidden-state\n",
    "    output = transformer_layer[1]\n",
    "    \n",
    "    #add meta data\n",
    "    # if use_meta:\n",
    "    #     output = tf.keras.layers.Concatenate()([output, meta_input])\n",
    "        \n",
    "    \n",
    "    #add dense relu layer\n",
    "    if add_dense:\n",
    "        print(\"Training with additional dense layer...\")\n",
    "        output = tf.keras.layers.Dense(dense_dim,activation='relu')(output)\n",
    "    \n",
    "    #add dropout\n",
    "    if add_dropout:\n",
    "        print(\"Training with dropout...\")\n",
    "        output = tf.keras.layers.Dropout(dropout)(output)\n",
    "    \n",
    "    #add final node for binary classification\n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n",
    "    \n",
    "    #assemble and compile\n",
    "#     if use_meta:\n",
    "#         print(\"Training with meta-data...\")\n",
    "#         model = tf.keras.models.Model(inputs = [input_ids,attention_masks, meta_input],outputs = output)\n",
    "    \n",
    "#     else:\n",
    "    print(\"Training without meta-data...\")\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6aa5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Tweets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/dgx914/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets encoded\n",
      "\n",
      "Train length: 27336\n",
      "Test length: 3038\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_BASE:\n",
    "    #get our inputs\n",
    "    print('Encoding Tweets...')\n",
    "    train_input_ids,train_attention_masks = bert_encode(X_train,60)\n",
    "    test_input_ids,test_attention_masks = bert_encode(X_test,60)\n",
    "    print('Tweets encoded')\n",
    "    print('')\n",
    "\n",
    "    #debugging step\n",
    "    print('Train length:', len(train_input_ids))\n",
    "    print('Test length:', len(test_input_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02ca2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with dropout...\n",
      "Training without meta-data...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 768)          0           tf_bert_model[1][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            769         dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,483,009\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/dgx914/.local/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "#and build and view parameters\n",
    "BERT_base = build_model(bert_base, learning_rate = 1e-5)\n",
    "BERT_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6fb0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('base_model.h5', monitor='val_loss', save_best_only = True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bea1423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "684/684 [==============================] - 1883s 3s/step - loss: 0.5561 - accuracy: 0.7100 - val_loss: 0.4932 - val_accuracy: 0.7643\n",
      "Epoch 2/8\n",
      "684/684 [==============================] - 1780s 3s/step - loss: 0.4522 - accuracy: 0.7919 - val_loss: 0.4903 - val_accuracy: 0.7723\n",
      "Epoch 3/8\n",
      "684/684 [==============================] - 1738s 3s/step - loss: 0.3753 - accuracy: 0.8373 - val_loss: 0.5466 - val_accuracy: 0.7650\n",
      "Epoch 4/8\n",
      "684/684 [==============================] - 1882s 3s/step - loss: 0.2741 - accuracy: 0.8876 - val_loss: 0.6186 - val_accuracy: 0.7683\n",
      "Epoch 5/8\n",
      "684/684 [==============================] - 2188s 3s/step - loss: 0.1835 - accuracy: 0.9289 - val_loss: 0.7889 - val_accuracy: 0.7522\n",
      "Epoch 6/8\n",
      "684/684 [==============================] - 2157s 3s/step - loss: 0.1198 - accuracy: 0.9563 - val_loss: 0.9025 - val_accuracy: 0.7513\n",
      "Epoch 7/8\n",
      "684/684 [==============================] - 2278s 3s/step - loss: 0.0811 - accuracy: 0.9711 - val_loss: 0.9944 - val_accuracy: 0.7515\n",
      "Epoch 8/8\n",
      "684/684 [==============================] - 1921s 3s/step - loss: 0.0648 - accuracy: 0.9772 - val_loss: 1.0640 - val_accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "#train BERT\n",
    "if TRAIN_BASE:\n",
    "    # if USE_META:\n",
    "    #     history = BERT_base.fit([train_input_ids,train_attention_masks, meta_train], train.target, validation_split = .2, epochs = EPOCHS, callbacks = [checkpoint], batch_size = BATCH_SIZE)\n",
    "    \n",
    "    # else:\n",
    "    history = BERT_base.fit([train_input_ids,train_attention_masks], y_train, validation_split = .2, epochs = EPOCHS, callbacks = [checkpoint], batch_size = BATCH_SIZE)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed025499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with BERT\n",
    "if TRAIN_BASE:\n",
    "    preds_base = BERT_base.predict([test_input_ids,test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0677c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely loving new american rejects album</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fearnecotton heyy could play either well fight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thefrasermills sorry like seeing sun try talk ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picked puppys crap annoyed poops pee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coughing lung ive since xmas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0       absolutely loving new american rejects album          1\n",
       "1  fearnecotton heyy could play either well fight...          1\n",
       "2  thefrasermills sorry like seeing sun try talk ...          1\n",
       "3               picked puppys crap annoyed poops pee          0\n",
       "4                       coughing lung ive since xmas          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame({'text': X_test, 'sentiment': y_test})\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e754891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de4ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE:\n",
    "    submission_base = pd.DataFrame()\n",
    "    submission_base['id'] = test_id\n",
    "    submission_base['prob'] = preds_base\n",
    "    submission_base['target'] = np.round(submission_base['prob']).astype(int)\n",
    "    submission_base.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ffc21c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_BASE:\n",
    "    submission_base = submission_base[['id', 'target']]\n",
    "\n",
    "    #save to disk\n",
    "    submission_base.to_csv('submission_bert_base.csv', index = False)\n",
    "    print('Submission saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f58dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(\"submission_bert_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c568db86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>3033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>3034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>3036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>3037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3038 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target\n",
       "0        0       1\n",
       "1        1       1\n",
       "2        2       0\n",
       "3        3       0\n",
       "4        4       0\n",
       "...    ...     ...\n",
       "3033  3033       0\n",
       "3034  3034       1\n",
       "3035  3035       0\n",
       "3036  3036       1\n",
       "3037  3037       0\n",
       "\n",
       "[3038 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f484a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
